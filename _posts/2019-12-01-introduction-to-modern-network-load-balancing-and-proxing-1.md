---
layout: post
title: 최신 네트워크 로드 밸런싱 및 프록시 - 로드밸런서 들어가기 Introduction to modern network load balancing and proxing #1
tags: [번역, 로드밸런서]
---

[Introduction to modern network load balancing and proxing](https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236)


최근에 현대적인 네트워크로드 밸런싱 및 프록시에 관한 입문용 교육 자료가 부족하다. 로드 밸런싱은 안정적인 분산 시스템을 구축하는 데 필요한 핵심 개념 중 하나다. 로드 밸런싱 및 프록시 서버에 대한 위키피디아 기사에는 일부 개념에 대한 개요가 포함되어 있지만 특히 최신 마이크로 서비스 아키텍처와 관련된 주제에 대한 유동적인 처리는 포함되어 있지 않다. 로드 밸런싱을 위한 구글 검색 결과는 전문 용어가 많고 세부적인 내용은 부족한 공급 업체 페이지만 보여줄 뿐이다.
이 글에서는 최신 네트워크로드 밸런싱 및 프록시를 간단히 소개해서 정보 부족을 바로 잡으려고 한다. 

## 네트워크 로드 밸런싱과 프록시란?
Wikipedia는 로드 밸런싱을 다음과 같이 [정의](https://en.wikipedia.org/wiki/Load_balancing_(computing))한다.

> 컴퓨팅에서 로드 밸런싱은 컴퓨터, 컴퓨터 클러스터, 네트워크 링크, 중앙 처리 장치 또는 디스크 드라이브와 같은 여러 컴퓨팅 리소스에서 워크로드 분산을 향상시킨다. 로드 밸런싱은 리소스 사용을 최적화하고 처리량을 최대화하며 응답 시간을 최소화하고 단일 리소스의 과부하를 방지하는 것을 목표로 한다. 단일 구성 요소 대신로드 균형 조정 기능이있는 여러 구성 요소를 사용하면 중복성을 통해 안정성과 가용성이 향상 될 수 있다. 로드 밸런싱에는 일반적으로 멀티 레이어 스위치 또는 도메인 이름 시스템 서버 프로세스와 같은 전용 소프트웨어 또는 하드웨어가 포함된다.

위의 정의는 네트워크뿐만 아니라 컴퓨팅의 모든 측면에 적용된다. 운영 체제는 로드 밸런싱을 사용하여 물리적 프로세서간에 작업을 예약하고 쿠버네티스와 같은 컨테이너 오케스트레이터는 로드 밸런싱을 사용하여 컴퓨팅 클러스터에서 작업을 예약하고, 네트워크로드 밸런서는 로드 밸런싱을 사용하여 사용 가능한 백엔드에서 네트워크 작업을 예약한다. 이 포스트의 나머지 부분에서는 네트워크로드 밸런싱 만 다룬다. 


![Figure 1](/images/posts/figure1-network-loadbalancing-overview.png)

그림 1은 네트워크로드 밸런싱에 대한 개괄적 인 개요를 보여준다. 일부 클라이언트가 일부 백엔드에서 리소스를 요청하고 있다. 로드 밸런서는 클라이언트와 백엔드 사이에 있으며 고수준에서 몇 가지 중요한 작업을 수행한다.

* 서비스 검색 : 시스템에서 어떤 백엔드를 사용할 수 있나? 그들의 주소는?(즉,로드 밸런서가 어떻게 통신해야 하나)?
* 상태 확인 : 현재 상태가 양호하고 요청을 수락 할 수있는 백엔드는 무엇인가?
* 부하 분산 : 정상적인 백엔드에서 개별 요청의 균형을 맞추려면 어떤 알고리즘을 사용해야 하나?
분산 시스템에서로드 밸런싱을 올바르게 사용하면 몇 가지 이점이 있다.


* 이름 지정 추상화 : 모든 백엔드 (서비스 검색)에 대해 알아야하는 모든 클라이언트 대신 클라이언트는 미리 정의 된 메커니즘을 통해로드 밸런서를 처리 한 다음 이름 확인 작업을로드 밸런서에 위임 할 수 있다. 사전 정의 된 메커니즘에는 내장 라이브러리 및 잘 알려진 DNS / IP / 포트 위치가 포함되며 아래에서 더 자세히 설명한다.
* 내결함성 : 상태 확인 및 다양한 알고리즘 기술을 통해 로드 밸런서는 불량 또는 과부하 된 백엔드를 효과적으로 라우팅 할 수 있다. 즉, 운영자는 일반적으로 여가 시간과 비상 상황에서 불량 백엔드를 수정할 수 있다.
* 비용 및 성능 이점 : 분산 시스템 네트워크는 거의 동질적이지 않다. 이 시스템은 여러 네트워크 영역과 지역에 걸쳐있을 수 있다. 영역 내에서 네트워크는 대개 상대적으로 가입이 부족한 방식으로 구축된다. 영역 간 초과 구독이 표준이 된다. (이 문맥에서 초과 가입 / 미달 가입은 라우터를 통해 사용 가능한 대역폭의 백분율로 NIC를 통해 소비 할 수있는 대역폭의 양을 나타낸다). 인텔리전트로드 밸런싱은 영역 내에서 요청 트래픽을 최대한 유지하여 성능을 높이고 (대기 시간 단축) 전반적인 시스템 비용을 줄인다 (영역간에 필요한 대역폭 및 파이버 감소).

## 로드밸런서 vs 프록시
네트워크 로드 밸런서에 관해 이야기 할 때,로드 밸런서 및 프록시라는 용어는 업계에서 거의 상호교환 적으로 사용됩니다. 이 게시물은 용어를 일반적으로 동등한 것으로 취급합니다. (모든 프록시가 기본적으로로드 밸런서 인 것은 아니지만 대부분의 프록시가 로드 밸런싱을 기본 기능으로 수행한다).
일부 사람들은 로드밸런싱이 임베디드 클라이언트 라이브러리의 일부로 사용될 때의 로드밸런서는 프록시가 아니라고 주장 한다. 그러나 나는 이런 구별이 이미 혼란스러운 주제에 불필요한 복잡성을 추가하는 것이라고 생각한다. 로드 밸런서 토폴로지 유형에 대해서는 아래에서 자세히 설명하지만 이 게시물에서는 내장된 로드 밸런서 토폴로지를 프록시의 특별경우로 취급한다. 애플리케이션은 애플리케이션 프로세스 외부에 있는 로드 밸런서와 동일한 추상화를 모두 제공하는 내장 라이브러리를 통해 프록시하고 있다.


## L4(커넥션/세션) 로드 밸런싱
오늘날 업계 전반의 로드 밸런싱에 대해 논의 할 때, 솔루션을 종종 L4와 L7의 두 가지 범주로 분류한다. 이 범주는 OSI 모델의 계층 4 및 계층 7을 참조한 것이다. 내가 L7 로드 밸런싱에 대해 논의할 때 분명해질 몇 가지 이유가 있는데, 그 때문에 나는 우리가 이러한 용어들을 사용하는데 불행이라고 생각한다. OSI 모델은 TCP 및 UDP와 같은 전통적인 계층 4 프로토콜을 포함하지만 다양한 OSI 계층에서 비트 및 프로토콜 조각을 포함하는 로드 밸런싱 솔루션의 복잡성을 대략적으로 근사한 수치다. 만약 L4 TCP 로드 밸런서가 TLS 종료도 지원한다면, 이것은 이제 L7로드 밸런서일까?


![Figure 2](/images/posts/figure2-TCP-L4-termination-load-balancing.png)

그림 2는 전통적인 L4 TCP 로드 밸런서를 보여준다. 이 경우 클라이언트는 로드 밸런서에 TCP 연결을 설정한다. 로드 밸런서는 연결을 종료하고 (즉, SYN에 직접 응답) 백엔드를 선택하고 백엔드에 대한 새로운 TCP 연결을 만든다 (즉, 새로운 SYN을 보낸다). 다이어그램의 세부 사항은 중요하지 않으며 L4로드 밸런싱 전용 섹션에서 자세히 설명한다.
이 섹션의 핵심은 L4로드 밸런서가 일반적으로 L4 TCP / UDP 연결 / 세션 수준에서만 작동한다는 것이다. 따라서 로드 밸런서는 대략 바이트를 앞뒤로 섞으며 동일한 세션의 바이트가 동일한 백엔드에서 감기도록 한다. L4로드 밸런서는 섞이는 바이트의 애플리케이션 세부 정보를 인식하지 못한다. 바이트는 HTTP, Redis, MongoDB 또는 기타 응용 프로그램 프로토콜일 수 있습니다.

## L7(어플리케이션) 로드 밸런싱
L4로드 밸런싱은 간단하지만 여전히 널리 사용된다. 그렇다면 L7 (애플리케이션)로드 밸런싱에 투자하게 만드는 L4로드 밸런싱의 단점은 무엇일까? 다음의 사례를 보자.

* 두 [gRPC](https://grpc.io/) / [HTTP2](https://en.wikipedia.org/wiki/HTTP/2) 클라이언트는 백엔드와 통신하여 L4로드 밸런서를 통해 연결하려 한다.
* L4로드 밸런서는 각 인커밍 TCP 연결에 대해 단일 아웃커밍 TCP 연결을 만들어 두 개의 인커밍 연결과 두 개의 아웃커밍 연결을 만든다.
* 그러나 클라이언트 A는 연결을 통해 분당 1 개의 요청 (RPM)을 전송하는 반면 클라이언트 B는 연결을 통해 초당 50 개의 요청 (RPS)을 전송한다.

이전 시나리오에서, 클라이언트 A를 처리하기 위해 선택한 백엔드는 클라이언트 B를 처리하기 위해 선택한 백엔드보다 약 3000 배 적은 부하를 처리한다! 큰문제다. 그리고 로드 밸런서 사용 목적도 상실했다. 이 문제는 멀티플렉싱 된 연결 유지 프로토콜에서 발생한다. (멀티플렉싱은 단일 L4 연결을 통해 동시 응용 프로그램 요청을 전송하는 것을 의미하며 활성 유지 요청은 활성 요청이 없을 때 연결을 닫지 않음을 의미함). 모든 최신 프로토콜은 효율성을 위해 멀티플렉싱 및 유지 기능으로 발전하고 있다 (특히 TLS를 사용하여 연결을 암호화하는 경우 연결을 생성하는 데 비용이 많이 든다). 따라서 L4로드 밸런서 임피던스 불일치는 시간이 지남에 따라 더욱 두드러진다. 이 문제는 L7로드 밸런서로 해결한다.


![Figure 3](/images/posts/figure3-http:2-l7-termination-load-balancing.png)

그림 3은 L7 HTTP / 2로드 밸런서를 보여준다. 이 경우 클라이언트는 로드 밸런서에 단일 HTTP / 2 TCP 연결을 설정한다. 그런 다음 로드 밸런서는 두 개의 백엔드 연결을 진행합니다. 클라이언트가 두 개의 HTTP / 2 스트림을로드 밸런서로 보내면 스트림 1은 백엔드 1로 전송되고 스트림 2는 백엔드 2로 전송된다. 따라서 요청로드가 크게 다른 멀티플렉싱 클라이언트도 백엔드 전체에서 효율적으로 균형을 맞 춘다. 이것이 현대 프로토콜에서 L7로드 밸런싱이 중요한 이유다. (L7로드 밸런싱은 애플리케이션 트래픽을 검사하는 기능으로 인해 엄청난 이점들을 제공하지만 아래에서 더 자세히 다룬다).

## L7 로드 밸런싱과 OSI 모델
위에서 L4로드 밸런싱 섹션에서 언급했듯이, 로드 밸런싱 기능을 설명하기 위해 OSI 모델을 사용하는 것은 문제가 된다. 그 이유는 적어도 OSI 모델에 의해 기술 된 바와 같이 L7 자체가 다수의 개별로드 밸런싱 추상화 계층을 포함하기 때문이다. 예를 들어 HTTP 트래픽의 경우 다음 하위 계층을 고려해야 한다.

* TLS (Transport Layer Security). 네트워킹 사람들은 어떤 OSI 계층 TLS에 속하는지 논쟁한다. 이 논의를 위해 TLS L7을 고려것이다,
* 물리적 HTTP 프로토콜 (HTTP / 1 또는 HTTP / 2).
* 논리적 HTTP 프로토콜 (헤더, 본문 데이터 및 예고편)
* 메시징 프로토콜 (gRPC, REST 등).

정교한 L7로드 밸런서는 위의 각 하위 계층과 관련된 기능을 제공 할 수 있다. 다른 L7로드 밸런서는 L7 범주에 배치하는 기능의 작은 하위 집합 만 가질 수 있다. 요컨대, L7로드 밸런서 환경은 L4 범주보다 기능 비교 관점에서 훨씬 더 복잡하다. (물론 이 섹션은 HTTP에 대해 다뤘다. Redis, Kafka, MongoDB 등은 L7로드 밸런싱의 혜택을 받는 L7 애플리케이션 프로토콜의 모든 예다).

## 로드 밸런서 기능
이 섹션에서는 로드 밸런서가 제공하는 고수준 기능을 간략하게 요약한다. 모든 로드 밸런서가 아래 기능을 제공하는 것은 아니다.
### 서비스 검색
서비스 검색은 로드 밸런서가 사용 가능한 백엔드 세트를 결정하는 프로세스이다. 방법은 매우 다양하며 아래는 일부 예시다.
* 정적 설정 파일.
* DNS.
* [주키퍼](https://zookeeper.apache.org/), [Etcd](https://etcd.io/), [Consul](https://www.consul.io/) 등
* Envoy의 [범용 데이터 플레인 API](https://blog.envoyproxy.io/the-universal-data-plane-api-d15cec7a).

### 헬스 체킹
헬스 체킹은 로드 밸런서가 백엔드의 트래픽 제공 가능 여부를 결정하는 프로세스이다. 헬스 체킹은 일반적으로 두 가지 범주로 나뉜다.
* 활성 :로드 밸런서는 규칙적인 간격 (예 : / healthcheck 엔드 포인트에 대한 HTTP 요청)으로 핑을 백엔드로 보내고 이를 사용하여 상태를 측정한다.
* 패시브 :로드 밸런서는 기본 데이터 흐름에서 상태를 감지한다. 예를 들어, L4로드 밸런서는 행에 3 개의 연결 오류가있는 경우 백엔드가 비정상이라고 판단 할 수 있다. L7로드 밸런서는 행에 세 개의 HTTP 503 응답 코드가있는 경우 백엔드가 비정상이라고 결정할 수 있다.

### 로드밸런싱
로드 밸런서는 로드 밸런싱 기능을 수행해야 한다. 정상적인 백엔드가 제공되면 연결 또는 요청을 처리 할 백엔드는 어떻게 선택될까? 로드 밸런싱 알고리즘은 활발한 연구 분야이며 랜덤 선택 및 라운드 로빈과 같은 단순한 알고리즘부터 가변 레이턴시 및 백엔드로드를 고려한 보다 복잡한 알고리즘에 이르기까지 다양합니다. 성능과 단순성을 고려한 가장 인기있는 로드 밸런싱 알고리즘 중 하나는 최소 요청로드 밸런싱으로 알려져 있다.

### Sticky session
특정 애플리케이션에서는 동일한 세션에 대한 요청이 동일한 백엔드에 도달하는 것이 중요하다. 이는 캐싱, 임시 복합 구성 상태 등과 관련이있을 수 있다. 세션 정의는 다양하며 HTTP 쿠키, 클라이언트 연결 속성 또는 기타 속성을 포함 할 수 있다. 많은 L7로드 밸런서는 고정 세션을 지원한다. Sticky session은 본질적으로 취약하기 때문에 (세션을 호스팅하는 백엔드는 죽을 수 있음), 이에 의존하는 시스템을 설계 할 때는 주의를 기울여야 한다.

### TLS 종료
엣지 서빙 및 서비스 간 통신 보안에서 TLS의 주제와 역할은 따로 포스팅 해도 될 정도로 중요하다. 많은 L7로드 밸런서는 종료, 인증서 확인 및 피닝, SNI를 사용한 인증서 제공 등을 포함한 많은 양의 TLS 처리를 수행한다.

### Observability
네트워크는 본질적으로 신뢰할 수 없으며 로드 밸런서는 종종 통계, 추적 및 로그를 내 보내서 운영자가 무엇이 잘못되었는지 파악하여 문제를 해결할 수 있도록 도와준다. 로드 밸런서는 관찰력 출력이 크게 다르다. 최첨단로드 밸런서는 숫자 통계, 분산 추적 및 사용자 정의 가능한 로깅을 포함하는 풍부한 출력을 제공한다. 향상된 관측성은 자유롭지 않다. 로드 밸런서는 이를 생성하기 위해 추가 작업을 수행해야 한다. 그러나 데이터의 이점은 상대적으로 작은 성능 영향보다 훨씬 크다.

### 보안과 Dos mitigation
특히 Edge 배포 토폴로지 (아래 참조)에서로드 밸런서는 속도 제한, 인증 및 DoS 완화 (예 : IP 주소 태깅 및 식별, 타 피팅 등)를 포함한 다양한 보안 기능을 구현한다.

### 설정과 제어평면(control plane)
로드 밸런서를 구성해야한다. 대규모 배포에서는 이 작업이 실질적인 작입이 될 수 있다. 일반적으로로드 밸런서를 구성하는 시스템을 "제어 평면(control plane)“이라고하며 구현 방식이 크게 다르다. 이 주제에 대한 자세한 내용은 서비스 메시 데이터 플레인(mesh data plane) 대 컨트롤 플레인(control plane)에 대한 포스팅을 참조하면 된다.

### 다른 것들
이 섹션에서는 로드 밸런서가 제공하는 기능 유형에 대한 표면적인 지식만 긁어왔다. 자세한 내용은 아래 L7로드 밸런서 섹션에서 확인할 수 있다.
